{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines import CoxPHFitter\n",
    "import lifelines\n",
    "import math\n",
    "import sys\n",
    "from statistics import stdev\n",
    "from lifelines.statistics import logrank_test, multivariate_logrank_test,pairwise_logrank_test\n",
    "\n",
    "# Set the path of SBL and merge1 files and read the files\n",
    "loc_data = \"/data_1/OAI_SBL_Analysis_Data/\"\n",
    "loc_module = \"/home/tsurendr/OAI_Github_scripts\"\n",
    "loc_data_SBL = loc_data + \"SBL_0904.csv\"\n",
    "loc_merge1 = loc_data + \"merge1_KL.csv\"\n",
    "raw_data_SBL = pd.read_csv(loc_data_SBL)\n",
    "merge1 = pd.read_csv(loc_merge1)\n",
    "# load custom module \n",
    "sys.path.append(loc_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbl_col_names = [\"F\" + str(i) for i in range(200)] + [\n",
    "    \"T\" + str(i) for i in range(200)\n",
    "]  # femur: F0~ F199 , tibia: T0 ~ T199\n",
    "sbl_col_names_femur = [\"F\" + str(i) for i in range(200)]\n",
    "sbl_col_names_tibia = [\"T\" + str(i) for i in range(200)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize with the following 3 variables:\n",
    "\n",
    "- data_SBL_both\n",
    "- data_SBL_femur\n",
    "- data_SBL_tibia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# normalize SBL for both femur and tibia at once #\n",
    "##################################\n",
    "raw_sbl_values = raw_data_SBL.loc[:, sbl_col_names].values\n",
    "sbl_values = np.empty_like(raw_sbl_values)  # for saving normalized SBL\n",
    "for row in range(raw_sbl_values.shape[0]):\n",
    "    sbl_values[row, :] = (\n",
    "        raw_sbl_values[row, :] / raw_sbl_values[row, :].mean()\n",
    "    )  # normalize by the averaged val. of SBL\n",
    "df_normalized_SBL = pd.DataFrame(sbl_values, columns=sbl_col_names)\n",
    "# get mean of Kellgren Lawrence (KL) grade 0\n",
    "sbl_KL_0_mean = df_normalized_SBL.loc[\n",
    "    (merge1[\"KL_Grade\"] == 0) , sbl_col_names\n",
    "].values.mean(0)\n",
    "print(f\"shape of sbl_KL_0_mean: {sbl_KL_0_mean.shape}\")\n",
    "baseline = sbl_KL_0_mean\n",
    "\n",
    "sbl_difference = df_normalized_SBL.loc[:, sbl_col_names].sub(baseline, axis=1)\n",
    "\n",
    "# sum of all the absolute value of sbl difference.\n",
    "sbl_difference_absolute = sbl_difference.abs()\n",
    "\n",
    "list_max = []\n",
    "for index, row in sbl_difference_absolute.iterrows():\n",
    "    #look for column in each row with biggest difference.\n",
    "    col_val = sbl_difference_absolute.idxmax()\n",
    "    val_list = []\n",
    "    for i in sbl_difference_absolute.columns:\n",
    "        val_list.append(sbl_difference_absolute.at[index,i])\n",
    "    val_list.sort(reverse=True)\n",
    "    top_percentile = val_list[0:400]\n",
    "    #now find the normalized SBL value in that column\n",
    "    sbl_normalized = (sum(top_percentile))\n",
    "    list_max.append(sbl_normalized)\n",
    "\n",
    "sbl_difference_absolute.name = \"normalized_sbl\"\n",
    "# Add sum of all the absolute value of sbl difference to data_SBL\n",
    "df_normalized_SBL_both = pd.DataFrame({'normalized_sbl':list_max})\n",
    "print(df_normalized_SBL_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# normalize SBL for femur #\n",
    "###########################\n",
    "raw_sbl_values = raw_data_SBL.loc[:, sbl_col_names_femur].values\n",
    "sbl_values = np.empty_like(raw_sbl_values)  # for saving normalized SBL\n",
    "for row in range(raw_sbl_values.shape[0]):\n",
    "    sbl_values[row, :] = (\n",
    "        raw_sbl_values[row, :] / raw_sbl_values[row, :].mean()\n",
    "    )  # normalize by the averaged val. of SBL\n",
    "df_normalized_SBL = pd.DataFrame(sbl_values, columns=sbl_col_names_femur)\n",
    "# get mean of Kellgren Lawrence (KL) grade 0\n",
    "sbl_KL_0_mean = df_normalized_SBL.loc[\n",
    "    (merge1[\"KL_Grade\"] == 0) , sbl_col_names_femur\n",
    "].values.mean(0)\n",
    "\n",
    "print(f\"shape of sbl_KL_0_mean: {sbl_KL_0_mean.shape}\")\n",
    "baseline = sbl_KL_0_mean\n",
    "\n",
    "sbl_difference = df_normalized_SBL.loc[:, sbl_col_names_femur].sub(baseline, axis=1)\n",
    "\n",
    "# sum of all the absolute value of sbl difference.\n",
    "sbl_difference_absolute = sbl_difference.abs()\n",
    "\n",
    "list_max = []\n",
    "for index, row in sbl_difference_absolute.iterrows():\n",
    "    #look for column in each row with biggest difference.\n",
    "    col_val = sbl_difference_absolute.idxmax()\n",
    "    val_list = []\n",
    "    for i in sbl_difference_absolute.columns:\n",
    "\n",
    "        val_list.append(sbl_difference_absolute.at[index,i])\n",
    "    val_list.sort(reverse=True)\n",
    "    top_percentile = val_list[0:200]\n",
    "\n",
    "    #now find the normalized SBL value in that column\n",
    "    sbl_normalized = (sum(top_percentile))\n",
    "    list_max.append(sbl_normalized)\n",
    "\n",
    "sbl_difference_absolute.name = \"normalized_sbl_femur\"\n",
    "# Add sum of all the absolute value of sbl difference to data_SBL\n",
    "df_normalized_SBL_femur = pd.DataFrame({'normalized_sbl_femur':list_max})\n",
    "print(df_normalized_SBL_femur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# normalize SBL for tibia #\n",
    "###########################\n",
    "raw_sbl_values = raw_data_SBL.loc[:, sbl_col_names_tibia].values\n",
    "sbl_values = np.empty_like(raw_sbl_values)  # for saving normalized SBL\n",
    "for row in range(raw_sbl_values.shape[0]):\n",
    "    sbl_values[row, :] = (\n",
    "        raw_sbl_values[row, :] / raw_sbl_values[row, :].mean()\n",
    "    )  # normalize by the averaged val. of SBL\n",
    "df_normalized_SBL = pd.DataFrame(sbl_values, columns=sbl_col_names_tibia)\n",
    "# get mean of Kellgren Lawrence (KL) grade 0\n",
    "sbl_KL_0_mean = df_normalized_SBL.loc[\n",
    "    (merge1[\"KL_Grade\"] == 0) , sbl_col_names_tibia\n",
    "].values.mean(0)\n",
    "print(f\"shape of sbl_KL_0_mean: {sbl_KL_0_mean.shape}\")\n",
    "baseline = sbl_KL_0_mean\n",
    "sbl_difference = df_normalized_SBL.loc[:, sbl_col_names_tibia].sub(baseline, axis=1)\n",
    "# sum of all the absolute value of sbl difference.\n",
    "sbl_difference_absolute = sbl_difference.abs()\n",
    "\n",
    "list_max = []\n",
    "for index, row in sbl_difference_absolute.iterrows():\n",
    "    #look for column in each row with biggest difference.\n",
    "    col_val = sbl_difference_absolute.idxmax()\n",
    "\n",
    "    val_list = []\n",
    "    for i in sbl_difference_absolute.columns:\n",
    "\n",
    "        val_list.append(sbl_difference_absolute.at[index,i])\n",
    "    val_list.sort(reverse=True)\n",
    "    top_percentile = val_list[0:200]\n",
    "\n",
    "    #now find the normalized SBL value in that column\n",
    "    sbl_normalized = (sum(top_percentile))\n",
    "\n",
    "    list_max.append(sbl_normalized)\n",
    "\n",
    "    \n",
    "sbl_difference_absolute.name = \"normalized_sbl_tibia\"\n",
    "# Add sum of all the absolute value of sbl difference to data_SBL\n",
    "df_normalized_SBL_tibia = pd.DataFrame({'normalized_sbl_tibia':list_max})\n",
    "print(df_normalized_SBL_tibia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining 3 Variables: df_normalized_SBL_both, df_normalized_SBL_femur, df_normalized_SBL_tibia\n",
    "data_SBL = pd.merge(\n",
    "    raw_data_SBL, df_normalized_SBL_both, right_index=True, left_index=True\n",
    ")  # merge df_normalized_SBL_both\n",
    "data_SBL = pd.merge(\n",
    "    data_SBL, df_normalized_SBL_femur, right_index=True, left_index=True\n",
    ")  # merge df_normalized_SBL_femur\n",
    "data_SBL = pd.merge(\n",
    "    data_SBL, df_normalized_SBL_tibia, right_index=True, left_index=True\n",
    ")  # merge df_normalized_SBL_tibia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data by knee side(right/left) and formatting columns appropriately \n",
    "\n",
    "print(\"total number of baseline knees\", len(data_SBL))\n",
    "data_SBL[\"id\"] = data_SBL[\"id\"].astype(str)\n",
    "data_BioMarkers = pd.read_csv(loc_data + \"Biomarker_data.csv\")\n",
    "data_SBL = data_SBL.drop([\"Unnamed: 0\"], axis=1)\n",
    "data_BioMarkers = data_BioMarkers.drop([\"Unnamed: 0\"], axis=1)\n",
    "side_SBL_temp = data_SBL.groupby(\"SIDE\")\n",
    "side_1_SBL_Right = side_SBL_temp.get_group(1)\n",
    "side_2_SBL_Left = side_SBL_temp.get_group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total number of right knees\", len(side_1_SBL_Right))\n",
    "print(\"total number of left knees\", len(side_2_SBL_Left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "NUM_YEARS = 11.0  \n",
    "encoding = \"utf-8\"\n",
    "# read and preprocessing\n",
    "raw_df = pd.read_sas(loc_data + \"outcomes99.sas7bdat\")\n",
    "# must censor data per knee\n",
    "print(\"Before data drop mri data\", len(raw_df))\n",
    "df = raw_df.dropna(axis=0, subset=[\"V99RNTCNT\"])\n",
    "print(\"complete mri data\", len(df))\n",
    "print(f\"number of drop: {len(raw_df)-len(df)}\")\n",
    "df = df.copy()\n",
    "df.loc[:, \"id\"] = df[\"id\"].apply(lambda x: str(x, encoding))\n",
    "\n",
    "merge1 = merge1.dropna(axis=0, subset=[\"P02SEX\"])\n",
    "merge1 = merge1.dropna(axis=0, subset=[\"V00AGE\"])\n",
    "merge1[\"id\"] = merge1[\"id\"].astype(str)\n",
    "merge1_temp = merge1.groupby(\"SIDE\")\n",
    "merge1_right = merge1_temp.get_group(1)\n",
    "merge1_left = merge1_temp.get_group(2)\n",
    "\n",
    "df_8_years = df[df[\"V99RNTCNT\"] <= NUM_YEARS].copy()  \n",
    "print(\"oai Data: \", len(df_8_years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL Grade information preprocessing for right knees\n",
    "\n",
    "data_KL_grade_right = pd.read_csv(loc_data + \"rightFilteredklMEAS.csv\")\n",
    "data_KL_grade_right = data_KL_grade_right.drop([\"Unnamed: 0\"], axis=1)\n",
    "data_KL_grade_right = data_KL_grade_right.dropna(axis=0, subset=[\"V00XRKLR\"])\n",
    "data_KL_grade_right[\"id\"] = data_KL_grade_right[\"id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL Grade information preprocessing for left knees\n",
    "\n",
    "\n",
    "data_KL_grade_left = pd.read_csv(loc_data + \"leftFilteredklMEAS.csv\")\n",
    "data_KL_grade_left = data_KL_grade_left.drop([\"Unnamed: 0\"], axis=1)\n",
    "data_KL_grade_left = data_KL_grade_left.dropna(axis=0, subset=[\"V00XRKLL\"])\n",
    "data_KL_grade_left[\"id\"] = data_KL_grade_left[\"id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BML information preprocessing for right knees. \n",
    "# right side\n",
    "data_BML_right = pd.read_csv(loc_data + \"rightFilteredbmlMoaks.csv\")\n",
    "data_BML_right[\"id\"] = data_BML_right[\"id\"].astype(str)\n",
    "data_BML_right = data_BML_right.drop([\"Unnamed: 0\"], axis=1)\n",
    "data_BML_right = data_BML_right.dropna(axis=0, subset=['V00MBMSFMA',\n",
    "'V00MBMSFLA',\n",
    "'V00MBMSFMC',\n",
    "'V00MBMSFLC',\n",
    "'V00MBMSFMP',\n",
    "'V00MBMSFLP',\n",
    "'V00MBMSSS',\n",
    "'V00MBMSTMA',\n",
    "'V00MBMSTLA',\n",
    "'V00MBMSTMC',\n",
    "'V00MBMSTLC',\n",
    "'V00MBMSTMP',\n",
    "'V00MBMSTLP'])\n",
    "\n",
    "# For verification after data processing\n",
    "print(\"bml right Data: \", len(data_BML_right))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all right knee info, including demographics, TKR, KL Grade, BML, etc...\n",
    "oai_bml_merge_right = pd.merge(df_8_years, data_BML_right, how=\"inner\", on=[\"id\"])\n",
    "oai_bml_SBL_KL_merge_right_pre = pd.merge(\n",
    "    oai_bml_merge_right, side_1_SBL_Right, how=\"inner\", on=[\"id\"]\n",
    ")\n",
    "print(len(oai_bml_SBL_KL_merge_right_pre))\n",
    "\n",
    "oai_bml_SBL_KL_merge_right_age_pre_1 = pd.merge(\n",
    "    oai_bml_SBL_KL_merge_right_pre, data_KL_grade_right, how=\"inner\", on=[\"id\"]\n",
    ")\n",
    "oai_bml_SBL_KL_merge_right = pd.merge(\n",
    "    oai_bml_SBL_KL_merge_right_age_pre_1, merge1_right, how=\"inner\", on=[\"id\"]\n",
    ")\n",
    "print(len(oai_bml_SBL_KL_merge_right))\n",
    "\n",
    "oai_bml_SBL_KL_merge_right.drop_duplicates(subset=[\"id\"], inplace=True, keep=\"last\")\n",
    "oai_bml_SBL_KL_merge_right.reset_index(drop=True, inplace=True)\n",
    "print(len(oai_bml_SBL_KL_merge_right))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BML information preprocessing for left knees. \n",
    "# left side\n",
    "data_BML_left = pd.read_csv(loc_data + \"leftFilteredbmlMoaks.csv\")\n",
    "data_BML_left[\"id\"] = data_BML_left[\"id\"].astype(str)\n",
    "data_BML_left = data_BML_left.drop([\"Unnamed: 0\"], axis=1)\n",
    "data_BML_left = data_BML_left.dropna(axis=0, subset=['V00MBMSFMA',\n",
    "'V00MBMSFLA',\n",
    "'V00MBMSFMC',\n",
    "'V00MBMSFLC',\n",
    "'V00MBMSFMP',\n",
    "'V00MBMSFLP',\n",
    "'V00MBMSSS',\n",
    "'V00MBMSTMA',\n",
    "'V00MBMSTLA',\n",
    "'V00MBMSTMC',\n",
    "'V00MBMSTLC',\n",
    "'V00MBMSTMP',\n",
    "'V00MBMSTLP'])\n",
    "\n",
    "# For verification after data processing\n",
    "print(\"bml left Data: \", len(data_BML_left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all left knee info, including demographics, TKR, KL Grade, BML, etc...\n",
    "oai_bml_merge_left = pd.merge(df_8_years, data_BML_left, how=\"inner\", on=[\"id\"])\n",
    "oai_bml_SBL_KL_merge_left_pre = pd.merge(\n",
    "    oai_bml_merge_left, side_2_SBL_Left, how=\"inner\", on=[\"id\"]\n",
    ")\n",
    "oai_bml_SBL_KL_merge_left_age_pre_1 = pd.merge(\n",
    "    oai_bml_SBL_KL_merge_left_pre, data_KL_grade_left, how=\"inner\", on=[\"id\"]\n",
    ") \n",
    "oai_bml_SBL_KL_merge_left = pd.merge(\n",
    "    oai_bml_SBL_KL_merge_left_age_pre_1, merge1_left, how=\"inner\", on=[\"id\"]\n",
    ")\n",
    "oai_bml_SBL_KL_merge_left.drop_duplicates(subset=[\"id\"], inplace=True, keep=\"last\")\n",
    "oai_bml_SBL_KL_merge_left.reset_index(drop=True, inplace=True)\n",
    "print(len(oai_bml_SBL_KL_merge_left))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process for restricting dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need 3 groups representing merged femur and tibia. \n",
    "\n",
    "femur_column_list = ['V00MBMSFMA',\n",
    "'V00MBMSFLA',\n",
    "'V00MBMSFMC',\n",
    "'V00MBMSFLC',\n",
    "'V00MBMSFMP',\n",
    "'V00MBMSFLP']\n",
    "\n",
    "tibia_column_list = ['V00MBMSSS',\n",
    "'V00MBMSTMA',\n",
    "'V00MBMSTLA',\n",
    "'V00MBMSTMC',\n",
    "'V00MBMSTLC',\n",
    "'V00MBMSTMP',\n",
    "'V00MBMSTLP']\n",
    "\n",
    "merged_column_list = ['V00MBMSFMA',\n",
    "'V00MBMSFLA',\n",
    "'V00MBMSFMC',\n",
    "'V00MBMSFLC',\n",
    "'V00MBMSFMP',\n",
    "'V00MBMSFLP',\n",
    "'V00MBMSSS',\n",
    "'V00MBMSTMA',\n",
    "'V00MBMSTLA',\n",
    "'V00MBMSTMC',\n",
    "'V00MBMSTLC',\n",
    "'V00MBMSTMP',\n",
    "'V00MBMSTLP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the largest BML in each knee based on if it is a Merged, Femur, or Tibia model\n",
    "# For both left and right knees\n",
    "\n",
    "# right side\n",
    "right_knee_tkr = oai_bml_SBL_KL_merge_right[\n",
    "    (oai_bml_SBL_KL_merge_right[\"V99RNTCNT\"] <= NUM_YEARS)\n",
    "    & (oai_bml_SBL_KL_merge_right[\"V99ERKDAYS\"].isnull() == False)\n",
    "]\n",
    "print(\"total knees on right side: \", len(oai_bml_SBL_KL_merge_right))\n",
    "print(\"censored right knees: \", len(oai_bml_SBL_KL_merge_right) - len(right_knee_tkr))\n",
    "print(\"proper right knee tkr: \", len(right_knee_tkr))\n",
    "\n",
    "oai_bml_SBL_KL_merge_right[\"right_tkr\"] = np.where(\n",
    "    oai_bml_SBL_KL_merge_right[\"id\"].isin(right_knee_tkr[\"id\"]) == True, 1, 0\n",
    ")\n",
    "oai_bml_SBL_KL_merge_right[\"bml_total_merged\"] = oai_bml_SBL_KL_merge_right[merged_column_list].max(axis=1)\n",
    "oai_bml_SBL_KL_merge_right[\"bml_total_femur\"] = oai_bml_SBL_KL_merge_right[femur_column_list].max(axis=1)\n",
    "oai_bml_SBL_KL_merge_right[\"bml_total_tibia\"] = oai_bml_SBL_KL_merge_right[tibia_column_list].max(axis=1)\n",
    "print(oai_bml_SBL_KL_merge_right[\"bml_total_merged\"].unique())\n",
    "\n",
    "\n",
    "# left side\n",
    "left_knee_tkr = oai_bml_SBL_KL_merge_left[\n",
    "    (oai_bml_SBL_KL_merge_left[\"V99RNTCNT\"] <= NUM_YEARS)\n",
    "    & (oai_bml_SBL_KL_merge_left[\"V99ELKDAYS\"].isnull() == False)\n",
    "]\n",
    "\n",
    "print(\"total knees on left side: \", len(oai_bml_SBL_KL_merge_left))\n",
    "print(\"censored left knees: \", len(oai_bml_SBL_KL_merge_left) - len(left_knee_tkr))\n",
    "print(\"proper left knee tkr: \", len(left_knee_tkr))\n",
    "\n",
    "\n",
    "oai_bml_SBL_KL_merge_left[\"right_tkr\"] = np.where(\n",
    "    oai_bml_SBL_KL_merge_left[\"id\"].isin(left_knee_tkr[\"id\"]) == True, 1, 0\n",
    ") \n",
    "\n",
    "oai_bml_SBL_KL_merge_left[\"bml_total_merged\"] = oai_bml_SBL_KL_merge_left[merged_column_list].max(axis = 1)\n",
    "oai_bml_SBL_KL_merge_left[\"bml_total_femur\"] = oai_bml_SBL_KL_merge_left[femur_column_list].max(axis = 1)\n",
    "oai_bml_SBL_KL_merge_left[\"bml_total_tibia\"] = oai_bml_SBL_KL_merge_left[tibia_column_list].max(axis = 1)\n",
    "print(oai_bml_SBL_KL_merge_left[\"bml_total_merged\"].unique())\n",
    "\n",
    "print(oai_bml_SBL_KL_merge_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining which patiets had a TKR and if not, what their most recent time of follow-up was.\n",
    "\n",
    "from time_adder import add_time\n",
    "\n",
    "oai_SBL_KL_BML_right = add_time(oai_bml_SBL_KL_merge_right, \"right\")\n",
    "oai_SBL_KL_BML_left = add_time(oai_bml_SBL_KL_merge_left, \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting columns from left and right knee info, to merge into 1 table for each SBL and BML model\n",
    "\n",
    "# right side\n",
    "oai_right_temp_SBL_Merged_right = oai_SBL_KL_BML_right[\n",
    "    ['id',\"time\", \"right_tkr\", \"P02SEX\", \"normalized_sbl\"]\n",
    "]\n",
    "oai_right_temp_SBL_Femur_right = oai_SBL_KL_BML_right[\n",
    "    ['id',\"time\", \"right_tkr\", \"P02SEX\", \"normalized_sbl_femur\"]\n",
    "]\n",
    "oai_right_temp_SBL_Tibia_right = oai_SBL_KL_BML_right[\n",
    "    ['id',\"time\", \"right_tkr\", \"P02SEX\", \"normalized_sbl_tibia\"]\n",
    "]\n",
    "oai_right_temp_BML_Merged_right = oai_SBL_KL_BML_right[\n",
    "    ['id',\"time\", \"right_tkr\", \"P02SEX\", \"bml_total_merged\"]\n",
    "]\n",
    "oai_right_temp_BML_Femur_right = oai_SBL_KL_BML_right[\n",
    "    ['id',\"time\", \"right_tkr\", \"P02SEX\", \"bml_total_femur\"]\n",
    "]\n",
    "oai_right_temp_BML_Tibia_right = oai_SBL_KL_BML_right[\n",
    "    ['id',\"time\", \"right_tkr\", \"P02SEX\", \"bml_total_tibia\"]\n",
    "]\n",
    "\n",
    "\n",
    "# left side\n",
    "oai_right_temp_SBL_Merged_left = oai_SBL_KL_BML_left[\n",
    "    ['id',\"time\", \"right_tkr\", \"P02SEX\", \"normalized_sbl\"]\n",
    "]\n",
    "oai_right_temp_SBL_Femur_left = oai_SBL_KL_BML_left[\n",
    "    ['id',\"time\", \"right_tkr\", \"P02SEX\", \"normalized_sbl_femur\"]\n",
    "]\n",
    "oai_right_temp_SBL_Tibia_left = oai_SBL_KL_BML_left[\n",
    "    ['id',\"time\", \"right_tkr\", \"P02SEX\", \"normalized_sbl_tibia\"]\n",
    "]\n",
    "oai_right_temp_BML_Merged_left = oai_SBL_KL_BML_left[\n",
    "    ['id',\"time\", \"right_tkr\", \"P02SEX\", \"bml_total_merged\"]\n",
    "]\n",
    "oai_right_temp_BML_Femur_left = oai_SBL_KL_BML_left[\n",
    "    ['id',\"time\", \"right_tkr\", \"P02SEX\", \"bml_total_femur\"]\n",
    "]\n",
    "oai_right_temp_BML_Tibia_left = oai_SBL_KL_BML_left[\n",
    "    ['id',\"time\", \"right_tkr\", \"P02SEX\", \"bml_total_tibia\"]\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging information for various SBL and BML models based on left and right knee information that was selected previously\n",
    "oai_right_temp_SBL_Merged_all = pd.concat(\n",
    "    [oai_right_temp_SBL_Merged_right, oai_right_temp_SBL_Merged_left],\n",
    "    ignore_index=True,\n",
    ")\n",
    "oai_right_temp_SBL_Femur_all = pd.concat(\n",
    "    [oai_right_temp_SBL_Femur_right, oai_right_temp_SBL_Femur_left],\n",
    "    ignore_index=True,\n",
    ")\n",
    "oai_right_temp_SBL_Tibia_all = pd.concat(\n",
    "    [oai_right_temp_SBL_Tibia_right, oai_right_temp_SBL_Tibia_left],\n",
    "    ignore_index=True,\n",
    ")\n",
    "oai_right_temp_BML_Merged_all = pd.concat(\n",
    "    [oai_right_temp_BML_Merged_right, oai_right_temp_BML_Merged_left],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "oai_right_temp_BML_Merged_all = pd.concat(\n",
    "    [oai_right_temp_BML_Merged_right, oai_right_temp_BML_Merged_left],\n",
    "    ignore_index=True,\n",
    ")\n",
    "oai_right_temp_BML_Femur_all = pd.concat(\n",
    "    [oai_right_temp_BML_Femur_right, oai_right_temp_BML_Femur_left],\n",
    "    ignore_index=True,\n",
    ")\n",
    "oai_right_temp_BML_Tibia_all = pd.concat(\n",
    "    [oai_right_temp_BML_Tibia_right, oai_right_temp_BML_Tibia_left],\n",
    "    ignore_index=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the left knee from patients who have 2 knees in the table in order to avoid confounding variables. \n",
    "\n",
    "\n",
    "oai_right_temp_SBL_Merged_all.drop_duplicates(subset = ['id'], keep = 'first', inplace = True) \n",
    "oai_right_temp_SBL_Femur_all.drop_duplicates(subset = ['id'], keep = 'first', inplace = True) \n",
    "oai_right_temp_SBL_Tibia_all.drop_duplicates(subset = ['id'], keep = 'first', inplace = True) \n",
    "oai_right_temp_BML_Merged_all.drop_duplicates(subset = ['id'], keep = 'first', inplace = True) \n",
    "oai_right_temp_BML_Femur_all.drop_duplicates(subset = ['id'], keep = 'first', inplace = True) \n",
    "oai_right_temp_BML_Tibia_all.drop_duplicates(subset = ['id'], keep = 'first', inplace = True) \n",
    "\n",
    "\n",
    "#Checking to make sure each patient has no more than 1 knee in the table\n",
    "print(len(list(set([x for i,x in enumerate(oai_right_temp_SBL_Femur_all['id'].tolist()) if oai_right_temp_SBL_Femur_all['id'].tolist().count(x) > 1]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_merged = oai_right_temp_SBL_Merged_all.groupby(\"P02SEX\")\n",
    "males_merged = groups_merged.get_group(1)\n",
    "females_merged = groups_merged.get_group(2)\n",
    "# check the gender population; male:1, female:2\n",
    "print(\"total males\", len(males_merged))\n",
    "print('total females', len(females_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Patients by SBL Difference Quartiles for Kaplan-Meier Analysis\n",
    "\n",
    "per_0, per_25, per_50, per_75, per_100 = np.quantile(sorted(oai_right_temp_SBL_Merged_all.normalized_sbl.tolist()),[0,0.25,0.5,0.75,1])\n",
    "less_25 = oai_right_temp_SBL_Merged_all.loc[oai_right_temp_SBL_Merged_all['normalized_sbl'] < per_25]\n",
    "to_50 = oai_right_temp_SBL_Merged_all.loc[(oai_right_temp_SBL_Merged_all['normalized_sbl'] < per_50) & (oai_right_temp_SBL_Merged_all['normalized_sbl'] >=  per_25)]\n",
    "to_75 = oai_right_temp_SBL_Merged_all.loc[(oai_right_temp_SBL_Merged_all['normalized_sbl'] <= per_75) & (oai_right_temp_SBL_Merged_all['normalized_sbl'] >= per_50 )]\n",
    "above_75 = oai_right_temp_SBL_Merged_all.loc[oai_right_temp_SBL_Merged_all['normalized_sbl'] > per_75]\n",
    "\n",
    "oai_right_temp_SBL_Merged_all.loc[oai_right_temp_SBL_Merged_all['normalized_sbl'] < per_25, 'SBL_Group'] = 0\n",
    "oai_right_temp_SBL_Merged_all.loc[(oai_right_temp_SBL_Merged_all['normalized_sbl'] < per_50) & (oai_right_temp_SBL_Merged_all['normalized_sbl'] >=  per_25), 'SBL_Group'] = 1\n",
    "oai_right_temp_SBL_Merged_all.loc[(oai_right_temp_SBL_Merged_all['normalized_sbl'] <= per_75) & (oai_right_temp_SBL_Merged_all['normalized_sbl'] >= per_50 ), 'SBL_Group'] = 2\n",
    "oai_right_temp_SBL_Merged_all.loc[oai_right_temp_SBL_Merged_all['normalized_sbl'] > per_75, 'SBL_Group'] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaplan Meier Analysis based on SBL Quartiles \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10.50, 3.50]\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(\n",
    "    durations=less_25[\"time\"],\n",
    "    event_observed=less_25[\"right_tkr\"],\n",
    "    label = '< 25 perentile SBL'\n",
    ")\n",
    "\n",
    "kmf.plot_survival_function(\n",
    "    show_censors=True,linestyle='solid', censor_styles={\"ms\": 6, \"marker\": \"X\"}\n",
    ")\n",
    "kmf1 = KaplanMeierFitter()\n",
    "kmf1.fit(\n",
    "    durations=to_50[\"time\"],\n",
    "    event_observed=to_50[\"right_tkr\"],\n",
    "    label = '25 - 49 Percentile SBL'\n",
    ")\n",
    "\n",
    "kmf1.plot_survival_function(\n",
    "    show_censors=True,linestyle='dotted', censor_styles={\"ms\": 6, \"marker\": \">\"}\n",
    ")\n",
    "kmf2 = KaplanMeierFitter()\n",
    "kmf2.fit(\n",
    "    durations=to_75[\"time\"],\n",
    "    event_observed=to_75[\"right_tkr\"],\n",
    "    label = '50 - 75 Percentile SBL'\n",
    ")\n",
    "\n",
    "kmf2.plot_survival_function(\n",
    "    show_censors=True,linestyle='dashdot', censor_styles={\"ms\": 6, \"marker\": \"<\"}\n",
    ")\n",
    "kmf3 = KaplanMeierFitter()\n",
    "kmf3.fit(\n",
    "    durations=above_75[\"time\"],\n",
    "    event_observed=above_75[\"right_tkr\"],\n",
    "    label = '> 75 Percentile SBL'\n",
    ")\n",
    "\n",
    "kmf3.plot_survival_function(\n",
    "    show_censors=True,linestyle='dashed',dashes=[10, 1, 10, 1], censor_styles={\"ms\": 6, \"marker\": \"o\"}\n",
    ")\n",
    "\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "plt.ylabel(\"Survival Probability\")\n",
    "\n",
    "plt.xlabel(\"Timeline (Days)\")\n",
    "plt.legend(loc = 'lower left')\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "add_at_risk_counts(kmf, kmf1, kmf2, kmf3)\n",
    "plt.savefig('/home/tsurendr/KMF_Curves/kmf_SBL.pdf', format='tif', bbox_inches = 'tight')\n",
    "\n",
    "#Log-rank test to compare the survival function between various SBL populations\n",
    "results_multivariate = pairwise_logrank_test(oai_right_temp_SBL_Merged_all['time'], oai_right_temp_SBL_Merged_all['SBL_Group'],oai_right_temp_SBL_Merged_all['right_tkr'])\n",
    "print(results_multivariate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('neuro': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c5ec2711fb9be5244b20562b562d0757efd7313fdacff057c04e89290da72bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
